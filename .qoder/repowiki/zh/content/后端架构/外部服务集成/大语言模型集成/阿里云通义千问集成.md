# 阿里云通义千问集成

<cite>
**Referenced Files in This Document**   
- [serverV2.py](file://serverV2.py)
- [config.json](file://config.json)
</cite>

## 目录
1. [简介](#简介)
2. [核心功能与架构](#核心功能与架构)
3. [阿里云通义千问集成实现](#阿里云通义千问集成实现)
4. [配置文件详解](#配置文件详解)
5. [错误处理与重试机制](#错误处理与重试机制)
6. [总结](#总结)

## 简介

本文档详细记录了AI有声书工具与阿里云通义千问大语言模型的集成实现。该系统通过 `serverV2.py` 文件中的 `generate_with_qwen` 函数，实现了将小说文本智能转换为有声书JSON格式的核心功能。整个流程依赖于 `config.json` 配置文件进行模型参数、API密钥和行为模式的动态管理，确保了系统的灵活性和可扩展性。

## 核心功能与架构

系统的核心功能是将用户上传的小说文本（`.txt`文件）转换为结构化的有声书JSON数据。该数据包含每个对话或旁白的说话者（speaker）、内容（content）、语气（tone）、强度（intensity）和停顿（delay）等信息，为后续的文本转语音（TTS）提供精确的指导。

系统架构采用模块化设计，主要由以下几个部分构成：
1.  **前端界面**：提供用户交互，用于上传小说、选择模型、预览和处理章节。
2.  **后端服务 (FastAPI)**：`serverV2.py` 文件是后端服务的核心，负责处理所有API请求，协调模型调用、文件操作和业务逻辑。
3.  **大语言模型 (LLM)**：作为“大脑”，负责理解文本并生成结构化JSON。系统支持多种模型，本文档重点介绍与阿里云通义千问的集成。
4.  **配置中心 (config.json)**：作为系统的“中枢神经”，集中管理所有模型的配置，包括API密钥、最大字符数、代理设置等。

这种架构使得模型的切换和配置变更变得简单，无需修改核心代码。

## 阿里云通义千问集成实现

与阿里云通义千问的集成主要通过 `serverV2.py` 文件中的 `generate_with_qwen` 函数实现。该函数的调用流程如下：首先，`process_single_chapter` 函数在处理章节时，会根据用户选择的模型名称（如 "aliyun"）调用 `generate_chapter_json` 函数。`generate_chapter_json` 函数会从 `config.json` 中读取对应的模型配置，并最终调用 `generate_with_qwen` 来执行与阿里云API的交互。

### API请求的动态构造

`generate_with_qwen` 函数根据 `config.json` 中的配置，动态构造发送给阿里云API的请求。其构造过程如下：

1.  **API端点 (API URL)**：函数使用固定的阿里云通义千问API端点：
    `https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation`

2.  **认证 (Authentication)**：使用 `Bearer` 令牌进行认证。函数从 `config.json` 中读取 `api_key`，并将其插入到请求头中：
    ```python
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    ```

3.  **请求头 (Headers)**：除了 `Authorization` 头，还设置了 `Content-Type` 为 `application/json`，以确保服务器正确解析请求体。

4.  **请求体 (Payload)**：请求体是一个JSON对象，其结构完全符合阿里云API的要求：
    *   **`model`**: 从 `config.json` 中读取 `model_name` 字段的值（例如 `deepseek-r1`），指定要调用的具体模型。
    *   **`input.messages`**: 这是一个消息数组，包含系统指令和用户请求。系统指令 (`role: "system"`) 告知模型其助手角色，用户请求 (`role: "user"`) 则是将 `PROMPT_TEMPLATE`（一个预定义的详细指令模板）与待处理的章节文本拼接而成。
    *   **`parameters.result_format`**: 这是关键参数。函数明确将其设置为 `"message"`，以确保API返回的是一个包含 `content` 字段的 `message` 对象，而不是其他格式。这保证了后续代码能够正确地从 `response_data["output"]["choices"][0]["message"]["content"]` 中提取出生成的文本。

5.  **超时机制 (Timeout)**：在发送 `requests.post` 请求时，设置了 `timeout=300`，即300秒的超时时间，以防止网络问题导致请求长时间挂起。

**Section sources**
- [serverV2.py](file://serverV2.py#L265-L278)

### 文本分块与异步处理

为了处理长篇小说章节，系统实现了智能的文本分块逻辑。

1.  **分块逻辑**：`generate_with_qwen` 函数首先调用 `smart_chunk_text` 函数对长章节进行分割。该函数会根据 `config.json` 中 `aliyun` 模型的 `max_chars` 配置（默认为6000）来确定每个文本块的最大长度。
2.  **智能分割**：`smart_chunk_text` 函数并非简单地按字符数截断，而是会向前查找最近的自然分割点（如换行符 `\n`、句号 `。`、感叹号 `！`、问号 `？` 等），以确保句子的完整性，避免在词语中间断开。
3.  **逐块发送**：分割后的文本块会被依次（在 `generate_with_qwen` 中是顺序处理）发送到阿里云API。函数内部通过一个循环，对每个文本块调用 `process_chunk` 内部函数，发起独立的API请求。
4.  **结果合并**：每个成功处理的文本块会返回一个JSON数组，`generate_with_qwen` 函数会将所有块的返回结果合并到一个大的 `all_json_parts` 列表中，最终返回给调用者。

**Section sources**
- [serverV2.py](file://serverV2.py#L264-L266)
- [serverV2.py](file://serverV2.py#L947-L984)

## 配置文件详解

`config.json` 文件是整个系统集成的核心，它定义了与阿里云通义千问交互所需的所有参数。

```json
{
  "models": {
    "aliyun": {
      "display_name": "阿里云平台",
      "model_name": "deepseek-r1",
      "api_key": "",
      "max_chars": 6000,
      "use_proxy": false
    }
  }
}
```

*   **`display_name`**: 在前端界面上显示的模型名称，便于用户识别。
*   **`model_name`**: **这是最重要的字段**。它必须填写阿里云DashScope平台上实际可用的模型ID，例如 `qwen-turbo`、`qwen-plus` 或 `qwen-max`。文档中示例的 `deepseek-r1` 是一个错误的示例，用户必须将其替换为正确的通义千问模型ID。
*   **`api_key`**: **这是身份凭证**。用户需要登录阿里云控制台，开通DashScope服务，并在“API密钥管理”页面创建一个API Key。然后，将生成的密钥字符串复制并粘贴到此字段中。
*   **`max_chars`**: 定义了发送给模型的单个请求的最大字符数。由于模型有输入长度限制，过长的文本必须分块。此值应根据所选模型的实际限制进行调整。
*   **`use_proxy`**: 一个布尔值，指示是否为此模型的请求启用代理。如果用户的网络环境需要通过代理访问外网，则应将其设置为 `true`，并在 `general.proxy` 部分配置代理地址和端口。

**Section sources**
- [config.json](file://config.json#L34-L40)

## 错误处理与重试机制

系统具备完善的错误处理能力，以应对网络波动或API服务不稳定的情况。

1.  **重试机制**：函数内部定义了 `MAX_RETRIES = 3`。对于每一个文本块的处理，如果API调用失败（如网络超时、服务器错误），函数会自动进行重试，最多尝试3次。每次重试前会等待5秒（`await asyncio.sleep(5)`），以避免对API造成过大压力。
2.  **响应解析**：函数使用 `validate_and_parse_json_array` 函数来解析API返回的内容。该函数会检查返回的文本是否以 `[` 开头、`]` 结尾（即有效的JSON数组），然后尝试用 `json.loads` 进行解析。如果解析失败，函数会认为响应无效。
3.  **代码块剥离**：考虑到某些模型的响应可能会将JSON内容包裹在Markdown代码块中（如 ```json ... ```），函数会检查返回的文本是否以 ` ```json` 开头。如果是，则会自动剥离前7个字符和后3个字符，只保留纯JSON内容，然后再进行解析。

**Section sources**
- [serverV2.py](file://serverV2.py#L187)
- [serverV2.py](file://serverV2.py#L280-L302)
- [serverV2.py](file://serverV2.py#L291-L293)
- [serverV2.py](file://serverV2.py#L511-L519)

## 总结

本文档详细阐述了AI有声书工具与阿里云通义千问大语言模型的集成方案。通过 `generate_with_qwen` 函数，系统能够根据 `config.json` 的配置，动态地构造符合阿里云API规范的请求，利用 `Bearer` 认证和 `result_format="message"` 参数确保通信的正确性。系统通过智能的文本分块和300秒超时机制，有效处理长篇内容，并通过3次重试和自动剥离代码块等机制，保障了服务的健壮性。正确配置 `config.json` 中的 `model_name` 和 `api_key` 是成功集成的关键。