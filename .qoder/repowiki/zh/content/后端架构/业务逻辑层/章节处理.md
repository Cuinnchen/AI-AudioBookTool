# 章节处理

<cite>
**Referenced Files in This Document**   
- [serverV2.py](file://serverV2.py)
- [config.json](file://config.json)
</cite>

## 目录
1. [简介](#简介)
2. [核心处理流程](#核心处理流程)
3. [LLM提示词与模型选择](#llm提示词与模型选择)
4. [文本分块策略](#文本分块策略)
5. [异常处理与数据校验](#异常处理与数据校验)
6. [结果清洗与存储](#结果清洗与存储)

## 简介
本文档深入解析了小说章节的智能分割与JSON结构化处理流程。该流程是AI有声书生成工具的核心环节，负责将原始的纯文本小说章节转换为包含说话者、内容、语气、强度和延迟等信息的结构化JSON数据，为后续的语音合成提供精确的指令。

## 核心处理流程

本流程的核心是`process_single_chapter`函数，它作为处理单个章节的入口点，协调了从文本读取、调用大模型分析到结果存储的完整生命周期。该函数首先从`source.txt`文件中读取指定章节的原始文本内容，然后根据请求参数决定是否进行预览或强制重新生成。

当进入正式处理模式时，函数会调用`generate_chapter_json`函数，传入章节内容和配置的模型名称。`generate_chapter_json`函数是整个流程的中枢，它负责读取`config.json`中的模型配置，根据`model_name`参数判断是使用Gemini还是阿里云（Aliyun）平台的大模型进行语义分析。

**Section sources**
- [serverV2.py](file://serverV2.py#L1081-L1229)
- [serverV2.py](file://serverV2.py#L560-L591)

## LLM提示词与模型选择

`PROMPT_TEMPLATE`是一个精心设计的系统提示词模板，它以指令的形式严格规定了大模型的输出格式和行为。该模板要求模型将输入的小说文本转换为一个标准的JSON数组，数组中的每个对象代表一个对话或旁白片段。

该模板详细定义了每个字段的含义和生成规则：
- **speaker**: 说话者姓名，需准确识别为“旁白”或具体角色名。
- **content**: 对话或旁白的原始内容，要求保持语义完整性，不修改、不遗漏。
- **tone**: 语气描述，如“愤怒”、“开心”等，由模型根据上下文推断。
- **intensity**: 情感强度，范围为1-10的整数。
- **delay**: 与上一句的停顿时间，以毫秒为单位。

此外，模板还包含了对长文本的处理规则，要求将超过100字的段落拆分为约50字的片段，并在自然停顿处（如句号、逗号）进行分割，以保证语义的连贯性。

**Section sources**
- [serverV2.py](file://serverV2.py#L152-L185)

## 文本分块策略

为了处理可能超出大模型上下文窗口的超长章节，系统实现了`smart_chunk_text`函数。该函数采用智能分块策略，确保在分割文本时不会破坏句子的完整性。

其分块逻辑如下：首先，它会尝试在预设的最大长度内，从后向前查找最佳的分割点。分割点的优先级顺序为：换行符 > 句号 > 感叹号 > 问号 > 分号 > 逗号。这种策略确保了文本总是在一个完整的句子或段落后被分割。如果在指定范围内找不到任何合适的标点符号，则作为最后手段，在最大长度处进行强制分割。这种策略在保证语义完整性的同时，也确保了所有文本都能被处理。

**Section sources**
- [serverV2.py](file://serverV2.py#L947-L984)

## 异常处理与数据校验

整个处理流程具备完善的异常处理和数据校验机制。在调用大模型API时，无论是Gemini还是阿里云，都实现了`MAX_RETRIES`（最大重试次数）机制。当API调用因网络问题或服务暂时不可用而失败时，系统会自动进行重试，直到成功或达到最大重试次数，从而提高了处理的鲁棒性。

对于大模型返回的响应，系统使用`validate_and_parse_json_array`函数进行严格的格式校验。该函数首先检查返回的文本是否以方括号`[`开头并以`]`结尾，然后尝试将其解析为JSON数组。如果校验失败（例如，模型返回了包含解释性文字的Markdown代码块），该函数会返回`None`，触发上层逻辑进行错误处理或重试，确保了输入到后续流程的数据是纯净且有效的JSON。

**Section sources**
- [serverV2.py](file://serverV2.py#L511-L518)
- [serverV2.py](file://serverV2.py#L265-L356)

## 结果清洗与存储

在获得大模型返回的原始JSON数据后，系统会通过`clean_json_content`函数进行清洗。该函数会移除那些`content`字段仅包含标点符号和空白字符的无效条目，避免生成无意义的静音片段。

清洗后的JSON数据最终被存储到`projects/{novel_name}/chapters_json/`目录下，文件名以章节标题命名。同时，系统会分析新出现的角色，并利用大模型生成其性别、年龄和身份等简介信息，存储在`character_profiles.json`文件中，为后续的语音合成提供角色特征参考。这一系列操作为后续的语音生成阶段提供了高质量、结构化的数据基础。

**Section sources**
- [serverV2.py](file://serverV2.py#L480-L509)
- [serverV2.py](file://serverV2.py#L1081-L1229)